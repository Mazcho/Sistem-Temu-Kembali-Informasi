{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5066da",
   "metadata": {},
   "source": [
    "Preprocesing Text menggunakan NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb253e74",
   "metadata": {},
   "source": [
    "Nicholaus Verdhy || A11.2020.12447"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f75aefc",
   "metadata": {},
   "source": [
    "# Penjelasan Singkat mengenai NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fb760",
   "metadata": {},
   "source": [
    "NLTK adalah kumpulan alat dan program yang digunakan untuk memproses dan menganalisis bahasa alami (NLP) dalam bahasa Inggris. Ini ditulis dalam bahasa pemrograman Python dan digunakan untuk tugas-tugas NLP yang melibatkan analisis teks dan statistik[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c46b4",
   "metadata": {},
   "source": [
    "# Project 1 : Preprocessing dengan NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4dbdb",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "210ccd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#Untuk Preprocessing Data nya\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9619270",
   "metadata": {},
   "source": [
    "Penjelasan untuk setiap library\n",
    "- `import re` digunakan untuk bekerja dengan ekspresi reguler (regular expressions), yang memungkinkan Anda untuk melakukan pencarian dan manipulasi teks berdasarkan pola-pola tertentu.digunakan untuk pencarian dan manipulasi teks berdasarkan pola pola tertentu\n",
    "- `import string` digunakan dalam manipulasi teks, seperti menghapus tanda baca atau mengoperasikan karakter-karakter tertentu \n",
    "- `import time` digunakan untuk bekerja dengan waktu dan tanggal dalam Python.\n",
    "- `import pandas` digunakan untuk memuat dataset yang ada\n",
    "- `from copy import deepcopy`  ini gunanya, ketika kita melakukan duplikasi dari objek, maka hasil duplikasinya adalah objek baru dan tidak terpengaruhi oleh objek lama\n",
    "- `from ekphrasis.classes.preprocessor import TextPreProcessor` untuk melakukan berbagai tugas pemrosesan teks, terutama pada teks yang berasal dari media sosial.\n",
    "- `from ekphrasis.classes.tokenizer import SocialTokenizer`adalah tokenizer yang digunakan untuk membagi teks menjadi kata-kata\n",
    "- `from ekphrasis.dicts.emoticons import emoticons` adalah kamus yang mungkin digunakan untuk mengganti emotikon dengan kata-kata yang sesuai.\n",
    "- `import nltk` adalah pernyataan impor untuk mengimpor modul NLTK (Natural Language Toolkit), yang merupakan pustaka yang digunakan dalam pemrosesan bahasa alami (NLP)\n",
    "- `from nltk.tokenize import word_tokenize` adalah salah satu alat dalam NLTK yang digunakan untuk membagi teks menjadi kata-kata atau token. \n",
    "- `import warning` mengabaikan warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ae4d8",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060cbac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset_Sentimen_Emosi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ecc78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Emosi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  Emosi\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0      1\n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0     -1\n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0      1\n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0     -2\n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0     -2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d94f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     904 non-null    object \n",
      " 1   Sentimen  903 non-null    float64\n",
      " 2   Emosi     904 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eccbe3",
   "metadata": {},
   "source": [
    "Deskripsi Kolom:\n",
    "\n",
    "`Tweet` : Isi hasil tweet orang di twiter\n",
    "\n",
    "`Sentimen`  : mengindikasikan sentimen atau perasaan yang terkait dengan setiap tweet. Sentimen dapat berupa positif, negatif, netral, atau mungkin memiliki label lebih rinci seperti senang, marah, sedih, dan lain-lain.\n",
    "\n",
    "`Emosi`      : sama seperti sentimen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579280d1",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9492424",
   "metadata": {},
   "source": [
    "Sumber modul : https://github.com/cbaziotis/ekphrasis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1bf2a",
   "metadata": {},
   "source": [
    "Modulnya ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf21aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9aed0",
   "metadata": {},
   "source": [
    "# Referensi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb86798",
   "metadata": {},
   "source": [
    "[1]\tE. J. Rifano, A. C. Fauzan, A. Makhi, E. Nadya, Z. Nasikin, and F. N. Putra, “Text Summarization Menggunakan Library Natural Language Toolkit (NLTK) Berbasis Pemrograman Python,” Ilk. J. Comput. Sci. Appl. Inform., vol. 2, no. 1, Art. no. 1, Apr. 2020, doi: 10.28926/ilkomnika.v2i1.32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc29c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
